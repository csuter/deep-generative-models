{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experimental study of \"saddle point formulation\"\n",
    "\n",
    "impact of architecture on robustness; \"model capacity important\"\n",
    "\n",
    "train on MNIST, CIFAR10; robust to adversarial attacks. 89% accuracy on MNIST, 46% on CIFAR10\n",
    "\n",
    "focus on $\\ell_\\infty$ ball perturbations\n",
    "\n",
    "Saddle point problem\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\rho(\\theta) \\quad \\mathrm{where} \\quad\n",
    "    \\rho(\\theta) = \\mathbb{E}_{(x,y) \\sim \\mathcal{D}} \\left[\n",
    "        \\max_{\\delta \\in \\mathcal{S}} L(\\theta, x + \\delta, y)\n",
    "    \\right]\n",
    "$$\n",
    "\n",
    "($\\mathcal{S}$ is an $\\ell_\\infty$-ball around $x$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import warnings\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "%pylab inline\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rc('image', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 71.685524 0.0827\n"
     ]
    }
   ],
   "source": [
    "def _(sess):\n",
    "  BATCH_SIZE=128\n",
    "\n",
    "  net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=None),\n",
    "  ])\n",
    "\n",
    "  x = tf.placeholder(tf.float32, [None, 28, 28], 'x')\n",
    "  y = tf.placeholder(tf.uint8, [None], 'y')\n",
    "  logits = net(x)\n",
    "  loss = tf.losses.softmax_cross_entropy(\n",
    "    tf.one_hot(y, 10), logits)\n",
    "  predictions = tf.cast(tf.argmax(tf.nn.softmax(logits), axis=-1), tf.uint8)\n",
    "\n",
    "  # Do some shape gymnastics to let us vectorize the computation of adversarial accuracies later\n",
    "  num_examples = tf.placeholder_with_default(np.int32(10000), [], 'num_examples')\n",
    "  eval_accuracy = tf.reduce_mean(tf.cast(\n",
    "    tf.equal(\n",
    "      tf.reshape(y, [-1, num_examples]),\n",
    "      tf.reshape(predictions, [-1, num_examples])),\n",
    "    tf.float32), axis=-1)\n",
    "\n",
    "  adam = tf.train.AdamOptimizer()\n",
    "  train_op = adam.minimize(loss)\n",
    "\n",
    "  NUM_ITERS = 10000\n",
    "  EVAL_INTERVAL = 1000\n",
    "  losses_ = np.zeros(NUM_ITERS, np.float32)\n",
    "  eval_loss_ = np.zeros(0, np.float32)\n",
    "  eval_accuracy_ = np.zeros(0, np.float32)\n",
    "\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for i in range(NUM_ITERS):\n",
    "    batch_indices = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
    "    feed_dict = {\n",
    "      x: x_train[batch_indices, ...],\n",
    "      y: y_train[batch_indices, ...],\n",
    "    }\n",
    "    _, losses_[i] = sess.run([train_op, loss], feed_dict)\n",
    "    if i % EVAL_INTERVAL == 0 or i + 1 == NUM_ITERS:\n",
    "      eval_accuracy_ = np.append(\n",
    "        eval_accuracy_,\n",
    "        sess.run(eval_accuracy, feed_dict={x: x_test, y: y_test}))\n",
    "      print(i, losses_[i], eval_accuracy_[-1])\n",
    "  plt.plot(losses_[10::EVAL_INTERVAL], label='Training Loss')\n",
    "  plt.plot(eval_accuracy_, label='Eval Accuracy')\n",
    "  plt.title(\"Training Loss and Eval Accuracy over Time\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  NUM_EPSILONS = 100\n",
    "  epsilons = np.linspace(0., 1., NUM_EPSILONS)[..., None, None, None]\n",
    "  adversaries = (x_test +\n",
    "                 epsilons * np.random.uniform(0., 255., size=[NUM_EPSILONS,\n",
    "                                                              x_test.shape[0],\n",
    "                                                              28, 28]))\n",
    "\n",
    "  rmse_ = np.sqrt(np.mean(np.reshape((x_test - adversaries)**2, [NUM_EPSILONS, -1]), axis=-1))\n",
    "  adversarial_eval_accuracies_ = sess.run(\n",
    "    eval_accuracy,\n",
    "    feed_dict={x: adversaries.reshape([-1, 28, 28]),\n",
    "               y: np.stack([y_test]*NUM_EPSILONS).reshape([-1])})\n",
    "  print(adversarial_eval_accuracies_.shape)\n",
    "  print(rmse_.shape)\n",
    "  plt.plot(epsilons, adversarial_eval_accuracies_)\n",
    "  plt.title(r\"Eval accuracy on adversaries as function of $\\epsilon$\")\n",
    "  plt.show()\n",
    "  plt.plot(epsilons, rmse_)\n",
    "  plt.title(r\"RMSE of adversarial perturbation as function of $\\epsilon$\")\n",
    "  plt.show()\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "  _(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jpy",
   "language": "python",
   "name": "jpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
